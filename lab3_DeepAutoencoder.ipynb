{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"images/DLI Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithmic Trading using Deep Autoencoder based Statistical Arbitrage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lab was developed by Onur Yilmaz, Ph.D."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Verification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we begin, let's verify WebSockets are working on your system. To do this, execute the cell block below by giving it focus (clicking on it with your mouse), and hitting Shift-Enter, or pressing the play button in the toolbar above. If all goes well, you should see some output returned below the grey cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The answer should be three: \" + str(1+2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's execute the cell below to display information about the GPUs running on the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Lab Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lab focuses on one of the popular algorithmic trading strategies, called Statistical Arbitrage. It utilizes deep autoencoders to generate trading signals for the 30 Dow Jones stocks.\n",
    "\n",
    "The goal of this lab is to give you a deep learning (DL) approach that can be potentially beneficial to the complex investment strategies in algorithmic trading. This lab is a complete algorithmic trading strategy that generates a profit and loss curve (P&L). It shows how deep autoencoder based deep neural networks can be applied to generate trading signals (long or short). The code provided in this lab can be used for a given portfolio.\n",
    "\n",
    "DL has been disrupting many applications including computer vision, natural language processing, and there has been a flurry of research and development activities in different verticals of the industry such as healthcare and finance to exploit this new technology for the area specific use cases. DL based investment strategies are also in the center of research and development activities in the algorithmic trading. \n",
    "\n",
    "In this lab, it is assumed that you are familiar with algorithmic trading, deep neural networks, TensorFlow, Keras, and Python. For more information on deep neural networks and TensorFlow, please check the relevant labs in DLI. \n",
    "\n",
    "In the third section, financial terminologies (particularly in algo-trading) are given. You can skip this section and directly start working on the hands-on exercises if you have already known these terms. Detailed information on the deep autoencoders are given in the fourth section. Step by step implementation of the strategy is given in the next section. Exercises, next steps and conclusions are given at the last part of the lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Algorithmic Trading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithmic trading (algo-trading) is the process of using computer programs designed to follow a strategy for placing a trade in order to generate profits at a speed and frequency that is impossible for a human trader. The algorithms in algo-trading use complex mathematical models, formulas, and statistics to develop new trading strategies. The algorithms are based on timing, price, quantity, and a variety of mathematical models. Apart from profit opportunities for the trader, algo-trading makes markets more liquid and makes trading more systematic by ruling out emotional human impacts on financial markets and trading activities. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terminology:\n",
    "\n",
    "Terminologies are directly taken from Investopedia.com [[1](http://www.investopedia.com/)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stock:** A stock is a type of security that signifies ownership in a corporation and represents a claim on part of the corporation's assets and earnings.It is delivered in the units of shares.\n",
    "\n",
    "**Share:** Shares are units of ownership interest in a corporation or financial asset.\n",
    "\n",
    "**Portfolio:** A portfolio is a grouping of financial assets such as stocks, bonds and cash equivalents.\n",
    "\n",
    "**Long Position (Long):** A long (or long position) is the buying of a security such as a stock, commodity or currency with the expectation that the asset will rise in value. Trader normally has no plan to sell the security in the near future. A key component of long position investment is the ownership of the stock or bond. \n",
    "    \n",
    "**Short Position (Short):** A short (or short position), is a directional trading or investment strategy where the investor sells shares of borrowed stock in the open market. The expectation of the investor is that the price of the stock will decrease over time, at which point the investor will purchase the shares in the open market and return the shares to the broker which he borrowed them from.\n",
    "\n",
    "**Return:** A return is the gain or loss of a security in a particular period. The return consists of the income and the capital gains relative on an investment, and it is usually quoted as a percentage. The general rule is that the more risk you take, the greater the potential for higher returns and losses.\n",
    "\n",
    "**Risk:** Risk involves the chance an investment's actual return will differ from the expected return. Risk includes the possibility of losing some or all of the original investment. Different versions of risk are usually measured by calculating the standard deviation of the historical returns or average returns of a specific investment.\n",
    "\n",
    "**Sharpe Ratio:** The Sharpe Ratio is a measure for calculating risk-adjusted return, and this ratio has become the industry standard for such calculations. It was developed by Nobel laureate William F. Sharpe. It is widely used to measure the performance of the strategy.\n",
    "\n",
    "**Mean Reversion:** Mean reversion is the theory suggesting that prices and returns eventually move back toward the mean or average. This mean or average can be the historical average of the price or return, or another relevant average such as the growth in the economy or the average return of an industry. \n",
    "\n",
    "A reversion involves the return of any condition back to a previous state. In cases of mean reversion, the thought is that any price that strays far from the long-term norm will again return, reverting to its understood state. The theory is focused on the reversion of only relatively extreme changes, as normal growth or other fluctuations are an expected part of the paradigm.\n",
    "\n",
    "This theory has led to many investing strategies involving the purchase or sale of stocks or other securities whose recent performances have greatly differed from their historical averages. However, a change in returns could be a sign that the company no longer has the same prospects it once did, in which case it is less likely that mean reversion will occur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pairs Trading:** Pairs trading is a market-neutral trading strategy that matches a long position with a short position in a pair of highly correlated instruments such as two stocks. A pairs trading strategy is centered on the concept of mean reversion. It waits for weakness in the correlation, and then go long on the under-performer while simultaneously going short on the over-performer, closing the positions as the relationship returns to its statistical norm. The strategyâ€™s profit is derived from the difference in price change (spread) between the two instruments, rather than from the direction in which each moves. Therefore, a profit can be realized if the long position goes up more than the short, or the short position goes down more than the long."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Statistical Arbitrage (Stat-arb):** At a basic level, arbitrage is the process of simultaneously buying and selling the same (or equivalent) securities on different markets to take advantage of price differences and make a profit. The price differences can be the result of market inefficiencies, pricing mismatches and even currency exchange rates.\n",
    "\n",
    "In stat-arb, a profit situation arises from pricing inefficiencies between securities. Investors identify the arbitrage situation through mathematical modeling techniques. It depends heavily on the ability of market prices to return to a historical or predicted normal. A spread is formed in stat-arb to make decisions to buy or sell it according to mathematical models and statistical analysis. It is also described as complex short-term mean-reversion strategy. Pairs trading can also fall under stat-arb.\n",
    "\n",
    "Principal component analysis (PCA) is widely used as a mathematical model to create a representation of the market (model) based on a given basket of assets (i.e. stocks). An the spread between market model and the individual asset return is measured for an arbitrage opportunity. Whenever the spread is large and expected to revert back to its mean value in the near future, a trading decision is made. \n",
    "\n",
    "In this lab, the goal is to use autoencoders (non-linear) instead of PCA (linear) to create the model for stat-arb. Detailed explanation and step by step implementation are given in Section 5.\n",
    "\n",
    "**Backtesting:** It is the process of testing a trading strategy on relevant historical data to ensure its viability before the trader risks any actual capital. A trader can simulate the trading of a strategy over an appropriate period of time and analyze the results for the levels of profitability and risk.\n",
    "\n",
    "### A Simple Mean-Reversion Based Algorithmic Trading Example:\n",
    "\n",
    "We will demonstrate a simple mean-reversion based trading strategy using Apple Inc.'s stock price (AAPL). All of the mean-reversion based strategies rely on a mean-reverting signal to generate a trading signal. Obtaining a mean-reverting signal is not a trivial task. Some of the simple trend following strategies utilize the ratio of short term moving averages (STMA) and long term moving averages (LTMA) to generate a mean-reverting signal while pairs trading utilizes correlation between two correlated stock returns. On the other hand, complex algo-trading strategies like stat-arb uses complex models to obtain a mean-reverting signal for each stock in the portfolio.\n",
    "\n",
    "In the following cell, we implemented a simple mean averages based strategy. Price, STMA, LTMA, mean-reverting signal, opened positions, and P&L are plotted for your review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "%matplotlib inline\n",
    "\n",
    "# Reading the price data from .xlsx file\n",
    "xl_aapl = pd.ExcelFile('/dli/tasks/task3/task/data/AAPL.xlsx')\n",
    "dfP_aapl = xl_aapl.parse('Sheet1')\n",
    "P_aapl = dfP_aapl.fillna(method=\"backfill\")\n",
    "P_aapl = np.array(P_aapl.drop('Date', axis=1))\n",
    "\n",
    "W_LTMA = 60\n",
    "W_STMA = 30\n",
    "T1_aaple = 0.03\n",
    "T2_aaple = 0.01\n",
    "\n",
    "[R_aaple, C_aaple] = P_aapl.shape\n",
    "dm = np.zeros(shape=(R_aaple-W_LTMA,3), dtype=float)\n",
    "mr = np.zeros(shape=(R_aaple-W_LTMA,1), dtype=float)\n",
    "pos_aaple = np.zeros(shape=(R_aaple-W_LTMA+1,1), dtype=int)\n",
    "p_apple_snap = 0.0\n",
    "PNL_apple = np.zeros(shape=(R_aaple-W_LTMA,1), dtype=float)\n",
    "\n",
    "idx = 0\n",
    "for i in range(W_LTMA, R_aaple):\n",
    "    ps = P_aapl[i-W_LTMA:i]\n",
    "    pf = P_aapl[i-W_STMA:i]\n",
    "    ms = np.mean(ps)\n",
    "    mf = np.mean(pf)\n",
    "    \n",
    "    dm[idx,0] = P_aapl[i]\n",
    "    dm[idx,1] = ms\n",
    "    dm[idx,2] = mf\n",
    "    mr[idx] = (mf/ms) - 1\n",
    "    \n",
    "    if pos_aaple[idx-1] == 0 and mr[idx] > T1_aaple:\n",
    "        # If the stock has no position and the spread of the ratio above the threshold T1\n",
    "        # Short position is opened because we expect the ratio will go down to get back its normal behaviour (mean)\n",
    "        pos_aaple[idx] = -1\n",
    "        p_apple_snap = P_aapl[i]\n",
    "    elif pos_aaple[idx-1] == 0 and mr[idx] < -T1_aaple:\n",
    "        # If the stock has no position and the spread of the error signal below the threshold -T1\n",
    "        # Long position is opened because we expect the stock will go up to get back its normal behaviour (mean)\n",
    "        pos_aaple[idx] = 1\n",
    "        p_apple_snap = P_aapl[i]\n",
    "    elif pos_aaple[idx-1] == -1 and mr[idx] < T2_aaple:\n",
    "        # If the stock is in short position and the spread is below threshold T2, \n",
    "        # that means it almost gets back to its normal behaviour and we close the position to generate profit\n",
    "        pos_aaple[idx] = 0\n",
    "        PNL_apple[idx] = -(P_aapl[i] - p_apple_snap)\n",
    "    elif pos_aaple[idx-1] == 1 and mr[idx] > -T2_aaple:\n",
    "        # If the stock is in long position and the spread is above threshold -T2, \n",
    "        # that means it almost gets back to its normal behaviour and we close the position to generate profit\n",
    "        pos_aaple[idx] = 0\n",
    "        PNL_apple[idx] = P_aapl[i] - p_apple_snap\n",
    "    else:\n",
    "        # Otherwise, no position is opened\n",
    "        pos_aaple[idx] = pos_aaple[idx-1]\n",
    "    \n",
    "    idx += 1\n",
    "    \n",
    "plt_p, = plt.plot(dm[:,0], label='Price')\n",
    "plt_ltma, = plt.plot(dm[:,1], label='LTMA')\n",
    "plt_stma, = plt.plot(dm[:,2], label='STMA')\n",
    "plt.legend(handles=[plt_p, plt_ltma, plt_stma])\n",
    "\n",
    "plt.title('AAPL')\n",
    "plt.ylabel('$')\n",
    "plt.xlabel('Days')\n",
    "plt.show()\n",
    "    \n",
    "plt.plot(mr)\n",
    "plt.title('AAPL')\n",
    "plt.ylabel('STMA/LTMA')\n",
    "plt.xlabel('Days')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(pos_aaple)\n",
    "plt.title('AAPL')\n",
    "plt.ylabel('Position')\n",
    "plt.xlabel('Days')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(np.cumsum(PNL_apple))\n",
    "plt.title('AAPL')\n",
    "plt.ylabel('PNL ($)')\n",
    "plt.xlabel('Days')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second figure above plots a signal which is the ratio of STMA and LTMA. This signal is reverting around mean zero. If the signal is below -T1, it longs the stock with the expectation of reverting back to normal. Similarly, if the signal is above T1, it shorts the stock. Third and the fourth figure above plot the opened positions and the P&L, respectively.\n",
    "\n",
    "Performance of the strategy heavily depend on the hyperparameters such as window size of long and short term moving average (W_STMA, W_LTMA), and threshold to open (T1) and close (T2) position.\n",
    "\n",
    "Let's set the short term average window as W_STMA = 20 and re-run the the cell.\n",
    "\n",
    "Was the P&L improved?\n",
    "\n",
    "As you noticed, P&L is improved. Although the algorithm is relatively simple, hyperparameter search is a non-trivial task.\n",
    "\n",
    "Moving average based mean-reverting algorithms were the workhorse of many algo-trading strategies in 1990s. But, they perform poorly in many situations like up or down trend in the price. That is why strategies like stat-arb use complex mathematical models to generate more reliable mean-reverting signals for trading.\n",
    "\n",
    "If you are interested in the technical details of these methods, we highly recommend you to check these references [[2](http://www.tandfonline.com/doi/abs/10.1080/14697680903124632), [3](https://www.elsevier.com/books/a-primer-for-financial-engineering/akansu/978-0-12-801561-2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. What is an Autoencoder?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"autoencoder.jpg\" width=\"700\" height=\"900\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                               Figure 1: (a) Autoencoder (b) Deep Autoencoder with 5 Layers\n",
    "                                            \n",
    "An autoencoder is an artificial neural network that tries to reconstruct its input. It is used for unsupervised learning. The goal of an autoencoder is to learn a representation (encoding) for a set of data, typically for the purpose of dimensionality reduction. Encoder generates latent features and decoder tries to reconstruct the input using latent features. Fig. 1 depicts (a) an autoencoder and (b) a deep autoencoder. Recently, the autoencoder concept has become more widely used for learning generative models of data. \n",
    "\n",
    "Architecturally, the simplest form of an autoencoder is a feedforward, non-recurrent neural network very similar to the multilayer perceptron (MLP), having an input layer, an output layer, and one or more hidden layers connecting them, but with the output layer having the same number of nodes as the input layer for the purpose of reconstructing its own inputs [[4](https://en.wikipedia.org/wiki/Autoencoder)].\n",
    "\n",
    "Principal component analysis (PCA) is a special autoencoder with linear activations. It has been the pillars of many applications in various industries including finance. PCA is also widely used in mathematical modeling for stat-arb. In this lab, we will explore the performance of deep autoencoders with non-linear activations in stat-arb.\n",
    "\n",
    "The code in the following cell draws an autoencoder with 5 layers. You can set different values to \"N_viz\" variable to change the size of the input and output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense\n",
    "import nnViz\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N_viz = 30\n",
    "hParams_viz = {}\n",
    "hParams_viz['inputOutputDimensionality'] = N_viz\n",
    "hParams_viz['hl1'] = np.int32(N_viz / 2)\n",
    "hParams_viz['hl2'] = np.int32(hParams_viz['hl1'] / 2)\n",
    "\n",
    "model_viz = Sequential()\n",
    "model_viz.add( Dense( hParams_viz['hl1'], input_dim = hParams_viz['inputOutputDimensionality'], activation = 'linear'))\n",
    "model_viz.add( Dense( hParams_viz['hl2'], activation = 'sigmoid'))\n",
    "model_viz.add( Dense( hParams_viz['hl1'], activation = 'sigmoid'))\n",
    "model_viz.add( Dense( hParams_viz['inputOutputDimensionality'], activation = 'linear',))\n",
    "model_viz.summary()\n",
    "    \n",
    "plt.figure()\n",
    "nnViz.visualize_model(model_viz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Backtesting the Deep Autoencoder based Stat-Arb Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we demonstrate the backtesting of deep autoencoder based statistical arbitrage strategy using Keras with TensorFlow backend. Our portfolio is comprised of 30 Dow Jones stocks. Historical adjusted close price of stocks is downloaded from [Yahoo Finance](https://finance.yahoo.com/) and split in time to create training and testing set. In algorithmic trading, backtesting with training set is usually performed for hyperparameter search.\n",
    "\n",
    "First, we import several widely used modules such as NumPy for numerical calculations, pandas for data management, matplotlib for visualizations, and Keras with TensorFlow backend for building and training deep neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense\n",
    "from keras import metrics\n",
    "from keras import initializers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions:\n",
    "\n",
    "Before we read the data and build the model, we defined the used functions in the lab. \n",
    "\n",
    "The \"getReturn\" function in the following cell calculates the log-return of assets. Typically, a price data matrix that includes price of single asset or multiple assets in different columns are passed as an input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getReturn(data):\n",
    "    [R, C] = data.shape\n",
    "    dataND = data[1:R]   \n",
    "    dataTD = data[0:R-1]\n",
    "    rts = np.log(np.divide(dataND, dataTD))\n",
    "    return rts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We standardize the log-returns (Z-score normalization) using the following function.  are normalized to zero mean and unit variance. One of the most commonly used technique, which is calculated using the arithmetic mean and standard deviation of the given data. Standardization is widely used in machine learning when the scale of the each feature in the set is different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeReturn(data):\n",
    "    data = np.divide((data - np.mean(data, axis=0)), np.std(data, axis=0)) \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"getTrainedAutoencoderModel\" function returns a trained model for the given model parameters and the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainedAutoencoderModel(hParams, trainData):\n",
    "    # 5 layers of deep autoencoder is defined\n",
    "    model = Sequential()\n",
    "    model.add( Dense( hParams['hl1'], input_dim = hParams['inputOutputDimensionality'], activation = 'linear'))\n",
    "    model.add( Dense( hParams['hl2'], activation = 'sigmoid'))\n",
    "    model.add( Dense( hParams['hl1'], activation = 'sigmoid'))\n",
    "    model.add( Dense( hParams['inputOutputDimensionality'], activation = 'linear',))\n",
    "    \n",
    "    model.compile(optimizer = 'adam', loss = 'mse')\n",
    "    early_stopping = EarlyStopping( monitor = 'val_loss', patience = 10)\n",
    "    checkpointer = ModelCheckpoint( filepath = 'synthetic_weights.hdf5', verbose=1, save_best_only = True)\n",
    "    \n",
    "    # Model is trained\n",
    "    model.fit( trainData,\n",
    "           trainData,\n",
    "           batch_size = hParams['batchSize'], \n",
    "           epochs = hParams['epochs'],\n",
    "           shuffle = True,\n",
    "           #callbacks = [early_stopping, checkpointer],\n",
    "           validation_data = (trainData, trainData),\n",
    "           verbose = 0 )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the current position, calculated spread, and the thresholds, trading signals will be generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genTradingSignals(pos, spread, Ts, Ss, Ps, N):\n",
    "    # Based on the spread, signal generation is similar to pairs trading \n",
    "    newPos = np.zeros(shape=(1, N), dtype=int) # New position for each stock will be stored in this vector\n",
    "    signal = np.zeros(shape=(1, N), dtype=int) # Generated signal to get to new position will be stored in this vector\n",
    "    totalOpenedPos = 0\n",
    "    \n",
    "    for stock in range(0, N):\n",
    "        if pos[stock] == Ps['NO_POSITION'] and spread[stock] > Ts['T1']:\n",
    "            # If the stock has no position and the spread of the error signal above the threshold T1\n",
    "            # Short position is opened because we expect the stock will go down to get back its normal behaviour (mean)\n",
    "            signal[0, stock] = Ss['SHORT_SELL']\n",
    "            newPos[0, stock] = Ps['SHORT']\n",
    "        elif pos[stock] == Ps['NO_POSITION'] and spread[stock] < -Ts['T1']:\n",
    "            # If the stock has no position and the spread of the error signal below the threshold -T1\n",
    "            # Long position is opened because we expect the stock will go up to get back its normal behaviour (mean)\n",
    "            signal[0, stock] = Ss['BUY']\n",
    "            newPos[0, stock] = Ps['LONG']\n",
    "        elif pos[stock] == Ps['SHORT'] and spread[stock] < Ts['T2']:\n",
    "            # If the stock is in short position and the spread is below threshold T2, \n",
    "            # that means it almost gets back to its normal behaviour and we close the position to generate profit\n",
    "            signal[0, stock] = Ss['BUY_TO_COVER']\n",
    "            newPos[0, stock] = Ps['NO_POSITION']\n",
    "        elif pos[stock] == Ps['LONG'] and spread[stock] > -Ts['T2']:\n",
    "            # If the stock is in long position and the spread is above threshold -T2, \n",
    "            # that means it almost gets back to its normal behaviour and we close the position to generate profit\n",
    "            signal[0, stock] = Ss['SELL']\n",
    "            newPos[0, stock] = Ps['NO_POSITION']\n",
    "        else:\n",
    "            # Otherwise, no position is opened\n",
    "            newPos[0, stock] = pos[stock]\n",
    "          \n",
    "        if newPos[0, stock] !=  Ps['NO_POSITION']:\n",
    "            totalOpenedPos += 1\n",
    "            \n",
    "    return (newPos, signal, totalOpenedPos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the trading signals are generated, they are sent to order execution unit. In this function, the orders will be executed, and profit and loss will be calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function executes the new orders, calculates the cost and P&L\n",
    "def executeOrders(signal, numOfShares, currentPrice, lastPriceSnap, tParam, Ss, N):\n",
    "    #P&L of each stock is stored in this vector\n",
    "    PNLAsset = np.zeros(shape=(1, N), dtype=float)\n",
    "    # This variables keeps the P&L of the portfolio\n",
    "    PNLTotal = 0.0\n",
    "    \n",
    "    for stock in range(0, N):\n",
    "        if signal[0, stock] == Ss['SHORT_SELL'] or signal[0, stock] == Ss['BUY']:\n",
    "            # New position will be opened\n",
    "            # Converting the investment amount to number of shares\n",
    "            nOfS = round(tParam['investPerAsset'] / currentPrice[0, stock])\n",
    "            # # Calculating the cost\n",
    "            cost = nOfS * tParam['tradingCostPerShare']\n",
    "            # Since new position is opening, there is no profit or loss, only the cost\n",
    "            PNLAsset[0, stock] = -cost \n",
    "            PNLTotal += PNLAsset[0, stock]\n",
    "            # Taking the snapshot of the purchase price\n",
    "            lastPriceSnap[0, stock] = currentPrice[0, stock]\n",
    "            # Storing the number of purchased shares\n",
    "            if signal[0, stock] == Ss['SHORT_SELL']:\n",
    "                numOfShares[0, stock] = -nOfS\n",
    "            else:\n",
    "                numOfShares[0, stock] = nOfS\n",
    "        elif signal[0, stock] == Ss['SELL'] or signal[0, stock] == Ss['BUY_TO_COVER']:\n",
    "            # Position will be closed\n",
    "            # Calculating the profit or loss\n",
    "            priceDiff = currentPrice[0, stock] - lastPriceSnap[0, stock]\n",
    "            # Calculating the cost\n",
    "            cost = numOfShares[0, stock] * tParam['tradingCostPerShare']\n",
    "            # Updating the P&L for the stock\n",
    "            PNLAsset[0, stock] = (priceDiff * numOfShares[0, stock]) - cost \n",
    "            # Updating the P&L of the portfolio\n",
    "            PNLTotal += PNLAsset[0, stock]\n",
    "            # Setting the number of stock to zero\n",
    "            numOfShares[0, stock] = 0\n",
    "            \n",
    "    return (PNLAsset, lastPriceSnap, numOfShares, PNLTotal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backtesting the Strategy\n",
    "\n",
    "Historical adjusted prices of 30 Dow Jones stocks are imported in the following cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the price data from .xlsx file\n",
    "xl = pd.ExcelFile('/dli/tasks/task3/task/data/DJI-AdjPrice-Train.xlsx')\n",
    "dfP = xl.parse('Sheet1')\n",
    "P = dfP.fillna(method=\"backfill\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"backtesting.jpg\" width=\"500\" height=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                        Figure 2: Sliding window in backtesting\n",
    "\n",
    "**Backtesting is comprised of 6 main steps;**\n",
    "\n",
    "Assuming the start time T=t-1\n",
    "\n",
    "1) Get the subset of the price data (P$_s$) for a given data window size as depicted in Fig. 2.\n",
    "\n",
    "2) Calculate the log-returns (R$_s$) of P$_s$\n",
    "\n",
    "3) Train a deep autoencoder using the R$_s$\n",
    "\n",
    "4) Perform an inference using the last row of R$_s$ and append the reconstruction errors to the matrix M.\n",
    "\n",
    "5) After pre-defined number of steps (error signal window), calculate the cumulative sum of reconstruction errors (M) for every stock, normalize and append the results to matrix S. Then, analyze the spread of error signal for every stock and generate trading signals.\n",
    "\n",
    "6) Slide the data window one sample down in time (t=t+1), and go back to step one.\n",
    "\n",
    "Main steps of the backtesting is implemented in the following cell. It might take 3-5 minutes to complete the backtesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The strategy will be run for a given subset of data \n",
    "# We will be sliding over the data with a sample after each trading cycle\n",
    "[R, C] = P.shape\n",
    "N = C - 1\n",
    "\n",
    "# Integer values to represent trade signals\n",
    "Ss = {}\n",
    "Ss['SELL'] = -1 # Sell the all the shares to close the position\n",
    "Ss['SHORT_SELL'] = -2 # Enter a short position\n",
    "Ss['BUY'] = 1 # Enter a long position\n",
    "Ss['BUY_TO_COVER'] = 2 # Buy shares to close the short position\n",
    "\n",
    "# Integer values to represent the current position of the assets\n",
    "Ps = {}\n",
    "Ps['NO_POSITION'] = 0\n",
    "Ps['SHORT'] = -1\n",
    "Ps['LONG'] = 1\n",
    "\n",
    "# Parameters of deep autoencoder. \n",
    "# In this case, we only use 5-layer autoencoder but you can try different models\n",
    "hParams = {}\n",
    "hParams['inputOutputDimensionality'] = N\n",
    "hParams['hl1'] = np.int32(N / 2)\n",
    "hParams['hl2'] = np.int32(hParams['hl1'] / 2)\n",
    "hParams['batchSize'] = 256\n",
    "hParams['epochs'] = 400\n",
    "\n",
    "# Window size to train the model\n",
    "TrainingSetSize = 200 # 200\n",
    "# Window size to calculate the spread of the error signal\n",
    "ErrorSignalWindow = 50 # 50\n",
    "\n",
    "# These are the threshold values that will be used in stat-arb strategy.\n",
    "# The first threshold, T1, is used to open a position.\n",
    "# The second threshold, T2, is used to close a position\n",
    "Ts = {}\n",
    "Ts['T1'] = 1.0 # Threshold for entering position\n",
    "Ts['T2'] = 0.6 # Threshold for exiting the position\n",
    "\n",
    "# Matrices are defined to store errors and spreads\n",
    "errors = np.empty((0,N))\n",
    "spread = np.empty((0,N))\n",
    "# Matrices to store current position, num of shares bought, PNL per asset, PNL of portfolio\n",
    "pos = np.zeros(shape=(1,N), dtype=int)\n",
    "numOfShares = np.zeros(shape=(1,N), dtype=int)\n",
    "lastPriceSnap = np.zeros(shape=(1,N), dtype=float)\n",
    "PNLPerAsset = np.zeros(shape=(1,N), dtype=float)\n",
    "PNLPortfolio = np.zeros(shape=(1, 1), dtype=float)\n",
    "PNLPortfolioTotal = 0.0\n",
    "\n",
    "# Parameters for the algorithmic trading strategy\n",
    "tParam ={}\n",
    "# Amount of money will be invested when entered a position.\n",
    "# If you would like to invest a different amount, please update the number\n",
    "tParam['investPerAsset'] = 5000 \n",
    "# Trading cost ($) per share. You can update the number based on your cost \n",
    "tParam['tradingCostPerShare'] = 0.005 \n",
    "\n",
    "idx = 0\n",
    "# Historical prices will be analyzed in a sliding window fashion\n",
    "# In each iteration, a subset of the data will be taken and analyzed \n",
    "for i in range(TrainingSetSize, R):\n",
    "    # Takes the subset of the price data for the row indeces between (i-TrainingSetSize) and i\n",
    "    pts = P[(i-TrainingSetSize):i].drop('Date', axis=1) \n",
    "    pts = np.array(pts)\n",
    "    rts = getReturn(pts) # Log-returns are calculated\n",
    "    rts = normalizeReturn(rts) # Log-returns are normalized\n",
    "    lastReturn = rts[rts.shape[0]-1:rts.shape[0]] # Last row of log-returns is stored to be used later\n",
    "        \n",
    "    print(\"Training %d\", idx)\n",
    "    # Deep autoencoder is trained using the log-returns\n",
    "    model = getTrainedAutoencoderModel(hParams, rts)\n",
    "    \n",
    "    # Last row of the log-returns is forward passed to measure its reconstruction error.\n",
    "    # And, these error values are stored in a matrix to analyze it\n",
    "    # This error will give us information about how the individual stock returns are deviating from the normal\n",
    "    # In other words, it is checking if there is anything anomalous in the stock.\n",
    "    # If there is an anomalous behavior in the stock, we will generate a position based on the expection of \n",
    "    # going back to normal\n",
    "    predReturn = model.predict(lastReturn)\n",
    "    err = np.subtract(lastReturn, predReturn)  \n",
    "    errors = np.vstack((errors, err))\n",
    "       \n",
    "    idx += 1\n",
    "    # After a certain number of iteration, the error signal is analzed to generate trade signals\n",
    "    # Again, sliding window approach is also applied \n",
    "    if idx > ErrorSignalWindow:\n",
    "        ce = np.shape(errors)[0]\n",
    "        # Get the last rows of the error signal for a given window size in \"ErrorSignalWindow\" variable\n",
    "        # Then, calculate the cumulative sum to see its mean reversion behavior\n",
    "        errsCum = np.cumsum(errors[ce-ErrorSignalWindow:ce], axis=0)\n",
    "        \n",
    "        cec = np.shape(errsCum)[0]\n",
    "        # Cumulative summed error signal is z-scored to understand the spread in normalized form\n",
    "        errsNorm = np.divide((errsCum[len(errsCum)-1] - np.mean(errsCum)), np.std(errsCum))  \n",
    "        spread = np.vstack((spread, errsNorm))\n",
    "        \n",
    "        # If the spread is below or above a certain threshold, trading signal is generated\n",
    "        newPos, signal, totalOpenedPos = genTradingSignals(pos[len(pos)-1], spread[len(spread)-1], Ts, Ss, Ps, N) \n",
    "        # After the new positions are calculated, they are executed and P&L info is returned\n",
    "        PNLAsset, lastPrice, nOfShares, PNLTotal = executeOrders(signal, \n",
    "                                                       numOfShares[len(numOfShares)-1:len(numOfShares)], \n",
    "                                                       pts[len(pts)-1:len(pts)], \n",
    "                                                       lastPriceSnap[len(lastPriceSnap)-1:len(lastPriceSnap)], \n",
    "                                                       tParam, \n",
    "                                                       Ss,\n",
    "                                                       N)\n",
    "        \n",
    "        # State (current position, number of shares, P&L, etc) of the strategy is stored \n",
    "        pos = np.vstack((pos, newPos))\n",
    "        lastPriceSnap = lastPrice\n",
    "        numOfShares = np.vstack((numOfShares, nOfShares))\n",
    "        PNLPerAsset = np.vstack((PNLPerAsset, PNLAsset))\n",
    "        PNLPortfolio = np.vstack((PNLPortfolio, PNLTotal))\n",
    "        PNLPortfolioTotal += PNLTotal\n",
    "        TotalInvestedEquity = totalOpenedPos * tParam['investPerAsset']\n",
    "        print(\"Invested Equity: %s, PNL Last Trade: %s, PNL Portfolio Total: %s\" % (TotalInvestedEquity, PNLTotal, PNLPortfolioTotal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Evaluations\n",
    "\n",
    "Stat-arb uses the spread in the error signal to generate a trade signal for an asset. It utilizes the mean-reversion feature of the error signal. If the error is below a threshold, it longs the stock with the expectation of reverting back to normal. Similarly, if the error is above a threshold, it shorts the stock. \n",
    "\n",
    "Performance of the strategy heavily depends on the hyperparameters. Such an algorithmic trading system usually spends significant amount of time on hyperparameter search by creating hundreds to thousands P&Ls and picks the parameters that works best for trading next minute, hour, day, etc. Multi GPU or multi node high performance systems are used for extensive hyperparameter searches. Here is the list of the hyperparameters;\n",
    "\n",
    "1) TrainingSetSize: Window size that defines how many samples we use from history for training our model\n",
    "\n",
    "2) ErrorSignalWindow: Window size that defines how many samples we use from error history to analyze the spread\n",
    "\n",
    "3) T1: The threshold that determines when to enter a position. If the spread in the error is above T1 or below -T1, new position is opened if there is no position opened before.\n",
    "\n",
    "4) T2: The threshold that determines when to close a position. If the spread in the error is above T2 or below -T2, open position is closed.\n",
    "\n",
    "5) Number of hidden layers: Number of layers in the deep autoencoder.\n",
    "\n",
    "6) epochs: full training cycle on the training set. Once every sample in the set is seen, you start again for the next epoch.\n",
    "\n",
    "We perform a backtesting for each hyperparameter combinations. There are well known methods for hyperparameter search like grid or random search. Once the hyperparameters that provide the best Sharpe ratio are found, they are used for a period of time on the algorithmic trading system. When that period which is another hyperparameter is completed, we start another search because market conditions change and we need to adopt the hyperparameter for the new conditions.\n",
    "\n",
    "For this lab, we set the hyperparameters intuitively without performing any search. Let's plot the error signal and the positions for a given stock id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assetID = 1\n",
    "\n",
    "plt.plot(spread[:,assetID])\n",
    "plt.ylabel('Spread')\n",
    "plt.xlabel('Days')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(pos[:,assetID])\n",
    "plt.ylabel('Positions (Long: 1, Short: -1, No Position: 0)')\n",
    "plt.xlabel('Days')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can change the assetID between 0-29 to see the error signal and positions of other stocks.\n",
    "\n",
    "Let's plot the profit and loss curve (P&L) of the strategy and calculate the annual Sharpe ratio to evaluate the performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annual Sharpe ratio is calculated\n",
    "SR = (np.mean(PNLPortfolio, axis=0) / np.std(PNLPortfolio, axis=0)) * math.sqrt(252)\n",
    "print(\"Annual SR: \", SR)\n",
    "\n",
    "cumPNLPortfolio = np.cumsum(PNLPortfolio, axis=0)\n",
    "plt.plot(cumPNLPortfolio)\n",
    "plt.ylabel('PNL ($)')\n",
    "plt.xlabel('Days')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each time you run this lab from scratch, you will likely get different Sharpe ratios even though the hyperparameters are the same. The reason behind this is that the optimization problem that is solved in training is non-convex. Because of this, the model might learn different weights (slightly different reconstruction as well) for the same training data. To control this, we suggest to add regularization into the optimization problem in the training. We leave this exercise up to you as a next step after this lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises:\n",
    "\n",
    "1) Set Ts['T1'] to 1.2 in the three above cell. Then re-run everything using Kernel->Restart & Run All.\n",
    "\n",
    "2) If you have enough time, you can try different hyperparameters to see if the Sharpe ratio is improving. Using the best performing hyperparameters, re-run everything for testing set. Change the data source to testing set by replacing the code \"xl = pd.ExcelFile('Data/DJI-AdjPrice-Train.xlsx')\" with \"xl = pd.ExcelFile('Data/DJI-AdjPrice-Test.xlsx')\" in four above cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. What is Next?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the lab, we recommend you doing the following options;\n",
    "\n",
    "1) Build a HPC system with multiple GPUs for overnight or real-time hyperparameter search.\n",
    "\n",
    "2) Develop the multi-GPU version of the code.\n",
    "\n",
    "3) Perform hyperparameter search periodically and use the best performing hyperparameters for a period (a day, a week, etc) because market conditions are changing and your hyperparameters need to adopt to market. How long should you use the optimum hyperparameters? That is also another hyperparameter.\n",
    "\n",
    "4) Try deeper autoencoders and see the performance.\n",
    "\n",
    "5) Add regularization to optimization in training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Post-Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, don't forget to save your work from this lab before time runs out and the instance shuts down!!\n",
    "\n",
    "You can execute the following cell block to zip the files you've been working on, and download it from the link below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -cvf output.zip \"Algorithmic Trading using Deep Autoencoder based Statistical Arbitrage.ipynb\" nnViz.py autoencoder.jpg backtesting.jpg data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Download output.zip](output.zip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"images/DLI Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
